---
title: "Abstract Generalised Networks"
---

**Motivation**

Neural networks start as empty architectures, made functional only by training data, after which they become static functions requiring continuous retraining to maintain performance. For static problems, like image classification (identifying a cat in a picture) or speech recognition (transcribing a spoken word) where the underlying data structure and relationships don't change over time, neural networks are very effective.

However, many real-world problems are dynamic, where the underlying data structure and relationships can evolve over time. In these scenarios, a static function (fixed neural network) often struggles to maintain performance. The ideal solution needs to be a dynamic function, able to adapt continuously and autonomously in real-time. 

**What are Abstract Generalised Networks?**

Abstract Generalised Networks (AGNs) are a proprietary AI architecture that functions as a world model. They provide AI systems with a dynamic internal representation of how a real-world environment evolves over time. This is achieved by modelling how information flows across different time frequencies.

AGNs infer the structure of an environment from the very first piece of information they receive, removing the traditional reliance on training data or fine-tuning. AGNs autonomously manipulate their underlying mathematical structure to anticipate directional change with respect to time and environment state. This makes AGNs an ideal foundational layer for building adaptive, intelligent systems.

**Architectural Design**

The architecture is built on a single principle: in any dynamic system, change begins at the highest observable time frequency before propagating to lower frequencies. 

AGNs are designed as a web of interconnected networks, where each observable timeframe is modelled by its own distinct AGN, and these individual networks interconnect to form the complete system. This graph design provides users the flexibility to isolate a single AGN for granular analysis or observe how information propagates across the entire network.

**Network Construction**

To effectively model a system's evolution, multiple timeframes are structured into two key networks:

- The Initiation Network, composed of higher-frequency AGNs, identifies the earliest signs of a new directional change.
- The Confirmation Network uses lower-frequency AGNs to validate these initial signals, confirming that the change is persisting and developing into a sustained trend.

<img
  src="/logo/propagate.png"
  alt="Network Propagation"
  height="300"
  className="rounded-lg mx-auto"
  style={{ width:"90%" }}
/>

<div style={{ textAlign:"center" }} />

**Data Processing**

While autoregressive models predict data point by point, an AGN processes an entire time window at once to infer its structure. This simultaneous analysis allows it to detect a fundamental structural shift the moment it appears, even if the time window only shifts by a single second (e.g., 16:14:00 to 16:14:01).

**Eliminating Analytical Blindspots**

A 1 step moving window is essential to the AGN's processing method. Since the architecture analyses the entire data window simultaneously, any jump larger than one step, such as a 5 step window, creates a blind spot where the exact moment of a directional change could be missed.

**Pinpointing the Directional Shift**

The first critical step is to identify the earliest directional change, which is the moment the indicator shifts from `-1` to `1` (or vice versa). While this shift often appears first on higher frequencies (e.g. on a 14 minute series before a 15 minute one), the key is finding the right balance. Overly high frequencies, such as 1 second, risk focusing on smaller fluctuations that don't reflect the broader, underlying change.

**Interpreting the Speed of Propagation**

The speed at which information propagates across timeframes is a key indicator of the underlying change's strength.

- Fast Propagation (Strong Change): A fast information propagation implies the start of a directional change starting from the highest frequency in the constructed network.
- Slow Propagation (Weak Change): A slow information propagation implies a missed opportunity. This is a diagnostic sign that the latency between the chosen timeframes is too high, requiring a higher-frequency network for earlier detection of similar events.

<img
  src="/logo/propagation_type.png"
  alt="Network Propagation Type"
  height="300"
  className="rounded-lg mx-auto"
  style={{ width:"90%" }}
/>

<div style={{ textAlign:"center" }} />

**Magnitude Within a Timeframe**

The magnitude of a change is determined by indicator consistency. A lone `1` indicator suggests a weak change, while a sustained series of `1`  indicators confirms a strong, persistent change, growing in strength as the chain lengthens.

**Non-Propagating Information**

An indicator that appears briefly on one timeframe but fails to propagate to a lower frequency typically indicates the exhaustion or end of a directional change.